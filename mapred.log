Fri  4 Oct 16:59:25 GMT 2019
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:28,835 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper1.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer1.py] [] /tmp/streamjob2033878369564690539.jar tmpDir=null
2019-10-04 16:59:29,454 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:29,515 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:29,515 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:29,532 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:29,708 INFO mapred.FileInputFormat: Total input files to process : 1
2019-10-04 16:59:29,738 INFO mapreduce.JobSubmitter: number of splits:1
2019-10-04 16:59:29,822 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1174265607_0001
2019-10-04 16:59:29,822 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-10-04 16:59:29,940 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper1.py as file:/tmp/hadoop-hadoop/mapred/local/job_local1174265607_0001_59120f81-85b4-44ed-bde8-f98da2324c04/mapper1.py
2019-10-04 16:59:29,950 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/reducer1.py as file:/tmp/hadoop-hadoop/mapred/local/job_local1174265607_0001_6a54a5ca-1c90-4ca6-b3b9-e044a408a492/reducer1.py
2019-10-04 16:59:29,999 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2019-10-04 16:59:30,000 INFO mapreduce.Job: Running job: job_local1174265607_0001
2019-10-04 16:59:30,000 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2019-10-04 16:59:30,002 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2019-10-04 16:59:30,004 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:30,004 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:30,052 INFO mapred.LocalJobRunner: Waiting for map tasks
2019-10-04 16:59:30,054 INFO mapred.LocalJobRunner: Starting task: attempt_local1174265607_0001_m_000000_0
2019-10-04 16:59:30,072 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:30,072 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:30,088 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:30,093 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/hadoop/input1.txt:0+37
2019-10-04 16:59:30,105 INFO mapred.MapTask: numReduceTasks: 1
2019-10-04 16:59:30,122 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-10-04 16:59:30,122 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-10-04 16:59:30,122 INFO mapred.MapTask: soft limit at 83886080
2019-10-04 16:59:30,122 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-10-04 16:59:30,122 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2019-10-04 16:59:30,124 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-10-04 16:59:30,129 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, mapper1.py]
2019-10-04 16:59:30,132 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2019-10-04 16:59:30,132 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2019-10-04 16:59:30,133 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2019-10-04 16:59:30,133 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2019-10-04 16:59:30,134 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2019-10-04 16:59:30,134 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2019-10-04 16:59:30,134 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2019-10-04 16:59:30,134 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2019-10-04 16:59:30,134 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2019-10-04 16:59:30,135 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2019-10-04 16:59:30,135 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2019-10-04 16:59:30,136 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2019-10-04 16:59:30,206 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:30,206 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:30,208 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:30,208 INFO streaming.PipeMapRed: Records R/W=10/1
2019-10-04 16:59:30,208 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:30,210 INFO mapred.LocalJobRunner: 
2019-10-04 16:59:30,210 INFO mapred.MapTask: Starting flush of map output
2019-10-04 16:59:30,211 INFO mapred.MapTask: Spilling map output
2019-10-04 16:59:30,211 INFO mapred.MapTask: bufstart = 0; bufend = 50; bufvoid = 104857600
2019-10-04 16:59:30,211 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2019-10-04 16:59:30,215 INFO mapred.MapTask: Finished spill 0
2019-10-04 16:59:30,225 INFO mapred.Task: Task:attempt_local1174265607_0001_m_000000_0 is done. And is in the process of committing
2019-10-04 16:59:30,227 INFO mapred.LocalJobRunner: Records R/W=10/1
2019-10-04 16:59:30,227 INFO mapred.Task: Task 'attempt_local1174265607_0001_m_000000_0' done.
2019-10-04 16:59:30,232 INFO mapred.Task: Final Counters for attempt_local1174265607_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=2540
		FILE: Number of bytes written=522987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=37
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=50
		Map output materialized bytes=76
		Input split bytes=96
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=238551040
	File Input Format Counters 
		Bytes Read=37
2019-10-04 16:59:30,232 INFO mapred.LocalJobRunner: Finishing task: attempt_local1174265607_0001_m_000000_0
2019-10-04 16:59:30,232 INFO mapred.LocalJobRunner: map task executor complete.
2019-10-04 16:59:30,234 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2019-10-04 16:59:30,235 INFO mapred.LocalJobRunner: Starting task: attempt_local1174265607_0001_r_000000_0
2019-10-04 16:59:30,239 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:30,240 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:30,240 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:30,243 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@536b5eee
2019-10-04 16:59:30,245 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:30,256 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=1941805440, maxSingleShuffleLimit=485451360, mergeThreshold=1281591680, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2019-10-04 16:59:30,258 INFO reduce.EventFetcher: attempt_local1174265607_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2019-10-04 16:59:30,276 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1174265607_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2019-10-04 16:59:30,279 INFO reduce.InMemoryMapOutput: Read 72 bytes from map-output for attempt_local1174265607_0001_m_000000_0
2019-10-04 16:59:30,280 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2019-10-04 16:59:30,281 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2019-10-04 16:59:30,282 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:30,282 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2019-10-04 16:59:30,287 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:30,287 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 66 bytes
2019-10-04 16:59:30,288 INFO reduce.MergeManagerImpl: Merged 1 segments, 72 bytes to disk to satisfy reduce memory limit
2019-10-04 16:59:30,289 INFO reduce.MergeManagerImpl: Merging 1 files, 76 bytes from disk
2019-10-04 16:59:30,289 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2019-10-04 16:59:30,289 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:30,290 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 66 bytes
2019-10-04 16:59:30,291 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:30,293 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, reducer1.py]
2019-10-04 16:59:30,295 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-10-04 16:59:30,296 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2019-10-04 16:59:30,332 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:30,332 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:30,335 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:30,335 INFO streaming.PipeMapRed: Records R/W=10/1
2019-10-04 16:59:30,341 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:30,388 INFO mapred.Task: Task:attempt_local1174265607_0001_r_000000_0 is done. And is in the process of committing
2019-10-04 16:59:30,389 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:30,390 INFO mapred.Task: Task attempt_local1174265607_0001_r_000000_0 is allowed to commit now
2019-10-04 16:59:30,404 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1174265607_0001_r_000000_0' to hdfs://localhost:9000/user/hadoop/mapred1
2019-10-04 16:59:30,405 INFO mapred.LocalJobRunner: Records R/W=10/1 > reduce
2019-10-04 16:59:30,405 INFO mapred.Task: Task 'attempt_local1174265607_0001_r_000000_0' done.
2019-10-04 16:59:30,405 INFO mapred.Task: Final Counters for attempt_local1174265607_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=2724
		FILE: Number of bytes written=523063
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=37
		HDFS: Number of bytes written=114
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=76
		Reduce input records=10
		Reduce output records=6
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=273678336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=114
2019-10-04 16:59:30,406 INFO mapred.LocalJobRunner: Finishing task: attempt_local1174265607_0001_r_000000_0
2019-10-04 16:59:30,406 INFO mapred.LocalJobRunner: reduce task executor complete.
2019-10-04 16:59:31,004 INFO mapreduce.Job: Job job_local1174265607_0001 running in uber mode : false
2019-10-04 16:59:31,006 INFO mapreduce.Job:  map 100% reduce 100%
2019-10-04 16:59:31,008 INFO mapreduce.Job: Job job_local1174265607_0001 completed successfully
2019-10-04 16:59:31,028 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=5264
		FILE: Number of bytes written=1046050
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=74
		HDFS: Number of bytes written=114
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=50
		Map output materialized bytes=76
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=76
		Reduce input records=10
		Reduce output records=6
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=512229376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=37
	File Output Format Counters 
		Bytes Written=114
2019-10-04 16:59:31,028 INFO streaming.StreamJob: Output directory: /user/hadoop/mapred1
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:35,430 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper2.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer2.py] [] /tmp/streamjob7273795905587691565.jar tmpDir=null
2019-10-04 16:59:36,062 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:36,105 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:36,106 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:36,123 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:36,290 INFO mapred.FileInputFormat: Total input files to process : 1
2019-10-04 16:59:36,318 INFO mapreduce.JobSubmitter: number of splits:1
2019-10-04 16:59:36,402 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local390709325_0001
2019-10-04 16:59:36,402 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-10-04 16:59:36,540 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper2.py as file:/tmp/hadoop-hadoop/mapred/local/job_local390709325_0001_3de58737-d3b8-4696-9d84-b9c3462d2204/mapper2.py
2019-10-04 16:59:36,550 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/reducer2.py as file:/tmp/hadoop-hadoop/mapred/local/job_local390709325_0001_60e5b7a4-5294-4ae2-9142-78855aa1555d/reducer2.py
2019-10-04 16:59:36,607 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2019-10-04 16:59:36,608 INFO mapreduce.Job: Running job: job_local390709325_0001
2019-10-04 16:59:36,609 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2019-10-04 16:59:36,610 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2019-10-04 16:59:36,613 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:36,613 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:36,651 INFO mapred.LocalJobRunner: Waiting for map tasks
2019-10-04 16:59:36,654 INFO mapred.LocalJobRunner: Starting task: attempt_local390709325_0001_m_000000_0
2019-10-04 16:59:36,672 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:36,672 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:36,688 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:36,694 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/hadoop/input2.txt:0+114
2019-10-04 16:59:36,705 INFO mapred.MapTask: numReduceTasks: 1
2019-10-04 16:59:36,722 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-10-04 16:59:36,722 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-10-04 16:59:36,722 INFO mapred.MapTask: soft limit at 83886080
2019-10-04 16:59:36,722 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-10-04 16:59:36,722 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2019-10-04 16:59:36,724 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-10-04 16:59:36,728 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, mapper2.py]
2019-10-04 16:59:36,732 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2019-10-04 16:59:36,732 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2019-10-04 16:59:36,733 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2019-10-04 16:59:36,733 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2019-10-04 16:59:36,733 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2019-10-04 16:59:36,733 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2019-10-04 16:59:36,734 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2019-10-04 16:59:36,734 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2019-10-04 16:59:36,734 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2019-10-04 16:59:36,735 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2019-10-04 16:59:36,735 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2019-10-04 16:59:36,735 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2019-10-04 16:59:36,807 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:36,809 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:36,809 INFO streaming.PipeMapRed: Records R/W=6/1
2019-10-04 16:59:36,810 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:36,813 INFO mapred.LocalJobRunner: 
2019-10-04 16:59:36,813 INFO mapred.MapTask: Starting flush of map output
2019-10-04 16:59:36,813 INFO mapred.MapTask: Spilling map output
2019-10-04 16:59:36,813 INFO mapred.MapTask: bufstart = 0; bufend = 231; bufvoid = 104857600
2019-10-04 16:59:36,813 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
2019-10-04 16:59:36,830 INFO mapred.MapTask: Finished spill 0
2019-10-04 16:59:36,839 INFO mapred.Task: Task:attempt_local390709325_0001_m_000000_0 is done. And is in the process of committing
2019-10-04 16:59:36,841 INFO mapred.LocalJobRunner: Records R/W=6/1
2019-10-04 16:59:36,842 INFO mapred.Task: Task 'attempt_local390709325_0001_m_000000_0' done.
2019-10-04 16:59:36,847 INFO mapred.Task: Final Counters for attempt_local390709325_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=1437
		FILE: Number of bytes written=519567
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=114
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=26
		Map output bytes=231
		Map output materialized bytes=289
		Input split bytes=96
		Combine input records=0
		Spilled Records=26
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=238026752
	File Input Format Counters 
		Bytes Read=114
2019-10-04 16:59:36,847 INFO mapred.LocalJobRunner: Finishing task: attempt_local390709325_0001_m_000000_0
2019-10-04 16:59:36,847 INFO mapred.LocalJobRunner: map task executor complete.
2019-10-04 16:59:36,849 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2019-10-04 16:59:36,850 INFO mapred.LocalJobRunner: Starting task: attempt_local390709325_0001_r_000000_0
2019-10-04 16:59:36,855 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:36,855 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:36,855 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:36,858 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49ae5b8e
2019-10-04 16:59:36,860 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:36,873 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=1941805440, maxSingleShuffleLimit=485451360, mergeThreshold=1281591680, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2019-10-04 16:59:36,875 INFO reduce.EventFetcher: attempt_local390709325_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2019-10-04 16:59:36,895 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local390709325_0001_m_000000_0 decomp: 285 len: 289 to MEMORY
2019-10-04 16:59:36,897 INFO reduce.InMemoryMapOutput: Read 285 bytes from map-output for attempt_local390709325_0001_m_000000_0
2019-10-04 16:59:36,899 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 285, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->285
2019-10-04 16:59:36,899 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2019-10-04 16:59:36,900 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:36,900 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2019-10-04 16:59:36,907 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:36,907 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 279 bytes
2019-10-04 16:59:36,908 INFO reduce.MergeManagerImpl: Merged 1 segments, 285 bytes to disk to satisfy reduce memory limit
2019-10-04 16:59:36,908 INFO reduce.MergeManagerImpl: Merging 1 files, 289 bytes from disk
2019-10-04 16:59:36,909 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2019-10-04 16:59:36,909 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:36,913 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 279 bytes
2019-10-04 16:59:36,913 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:36,916 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, reducer2.py]
2019-10-04 16:59:36,919 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-10-04 16:59:36,920 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2019-10-04 16:59:36,971 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:36,971 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:36,974 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:36,974 INFO streaming.PipeMapRed: Records R/W=26/1
2019-10-04 16:59:36,974 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:37,021 INFO mapred.Task: Task:attempt_local390709325_0001_r_000000_0 is done. And is in the process of committing
2019-10-04 16:59:37,023 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:37,023 INFO mapred.Task: Task attempt_local390709325_0001_r_000000_0 is allowed to commit now
2019-10-04 16:59:37,038 INFO output.FileOutputCommitter: Saved output of task 'attempt_local390709325_0001_r_000000_0' to hdfs://localhost:9000/user/hadoop/mapred2
2019-10-04 16:59:37,038 INFO mapred.LocalJobRunner: Records R/W=26/1 > reduce
2019-10-04 16:59:37,038 INFO mapred.Task: Task 'attempt_local390709325_0001_r_000000_0' done.
2019-10-04 16:59:37,039 INFO mapred.Task: Final Counters for attempt_local390709325_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=2047
		FILE: Number of bytes written=519856
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=114
		HDFS: Number of bytes written=114
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=289
		Reduce input records=26
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=274202624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=114
2019-10-04 16:59:37,039 INFO mapred.LocalJobRunner: Finishing task: attempt_local390709325_0001_r_000000_0
2019-10-04 16:59:37,039 INFO mapred.LocalJobRunner: reduce task executor complete.
2019-10-04 16:59:37,612 INFO mapreduce.Job: Job job_local390709325_0001 running in uber mode : false
2019-10-04 16:59:37,614 INFO mapreduce.Job:  map 100% reduce 100%
2019-10-04 16:59:37,616 INFO mapreduce.Job: Job job_local390709325_0001 completed successfully
2019-10-04 16:59:37,625 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=3484
		FILE: Number of bytes written=1039423
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=228
		HDFS: Number of bytes written=114
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=26
		Map output bytes=231
		Map output materialized bytes=289
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=289
		Reduce input records=26
		Reduce output records=6
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=512229376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=114
	File Output Format Counters 
		Bytes Written=114
2019-10-04 16:59:37,625 INFO streaming.StreamJob: Output directory: /user/hadoop/mapred2
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:42,049 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob2459228326192026454.jar tmpDir=null
2019-10-04 16:59:42,649 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:42,702 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:42,702 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:42,722 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:42,889 INFO mapred.FileInputFormat: Total input files to process : 1
2019-10-04 16:59:42,917 INFO mapreduce.JobSubmitter: number of splits:1
2019-10-04 16:59:43,010 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1647475249_0001
2019-10-04 16:59:43,010 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-10-04 16:59:43,139 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py as file:/tmp/hadoop-hadoop/mapred/local/job_local1647475249_0001_5067b34f-564f-4488-ab85-abdc8c255955/mapper3.py
2019-10-04 16:59:43,149 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py as file:/tmp/hadoop-hadoop/mapred/local/job_local1647475249_0001_904b282c-6d1e-4023-b920-26a5e452c5f9/reducer3.py
2019-10-04 16:59:43,204 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2019-10-04 16:59:43,205 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2019-10-04 16:59:43,205 INFO mapreduce.Job: Running job: job_local1647475249_0001
2019-10-04 16:59:43,206 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2019-10-04 16:59:43,209 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:43,209 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:43,245 INFO mapred.LocalJobRunner: Waiting for map tasks
2019-10-04 16:59:43,247 INFO mapred.LocalJobRunner: Starting task: attempt_local1647475249_0001_m_000000_0
2019-10-04 16:59:43,263 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:43,263 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:43,277 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:43,282 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/hadoop/input3.txt:0+134
2019-10-04 16:59:43,292 INFO mapred.MapTask: numReduceTasks: 1
2019-10-04 16:59:43,306 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-10-04 16:59:43,306 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-10-04 16:59:43,306 INFO mapred.MapTask: soft limit at 83886080
2019-10-04 16:59:43,306 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-10-04 16:59:43,306 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2019-10-04 16:59:43,308 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-10-04 16:59:43,312 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, mapper3.py]
2019-10-04 16:59:43,316 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2019-10-04 16:59:43,316 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2019-10-04 16:59:43,317 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2019-10-04 16:59:43,317 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2019-10-04 16:59:43,317 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2019-10-04 16:59:43,317 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2019-10-04 16:59:43,318 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2019-10-04 16:59:43,318 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2019-10-04 16:59:43,318 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2019-10-04 16:59:43,319 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2019-10-04 16:59:43,319 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2019-10-04 16:59:43,319 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2019-10-04 16:59:43,384 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:43,384 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:43,386 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:43,386 INFO streaming.PipeMapRed: Records R/W=11/1
2019-10-04 16:59:43,387 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:43,389 INFO mapred.LocalJobRunner: 
2019-10-04 16:59:43,389 INFO mapred.MapTask: Starting flush of map output
2019-10-04 16:59:43,389 INFO mapred.MapTask: Spilling map output
2019-10-04 16:59:43,389 INFO mapred.MapTask: bufstart = 0; bufend = 683; bufvoid = 104857600
2019-10-04 16:59:43,389 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
2019-10-04 16:59:43,394 INFO mapred.MapTask: Finished spill 0
2019-10-04 16:59:43,402 INFO mapred.Task: Task:attempt_local1647475249_0001_m_000000_0 is done. And is in the process of committing
2019-10-04 16:59:43,404 INFO mapred.LocalJobRunner: Records R/W=11/1
2019-10-04 16:59:43,404 INFO mapred.Task: Task 'attempt_local1647475249_0001_m_000000_0' done.
2019-10-04 16:59:43,410 INFO mapred.Task: Final Counters for attempt_local1647475249_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=2636
		FILE: Number of bytes written=523794
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=11
		Map output records=50
		Map output bytes=683
		Map output materialized bytes=789
		Input split bytes=96
		Combine input records=0
		Spilled Records=50
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=237502464
	File Input Format Counters 
		Bytes Read=134
2019-10-04 16:59:43,410 INFO mapred.LocalJobRunner: Finishing task: attempt_local1647475249_0001_m_000000_0
2019-10-04 16:59:43,410 INFO mapred.LocalJobRunner: map task executor complete.
2019-10-04 16:59:43,412 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2019-10-04 16:59:43,413 INFO mapred.LocalJobRunner: Starting task: attempt_local1647475249_0001_r_000000_0
2019-10-04 16:59:43,417 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-10-04 16:59:43,417 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-10-04 16:59:43,418 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-10-04 16:59:43,420 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@501afcb6
2019-10-04 16:59:43,421 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:43,432 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=1941805440, maxSingleShuffleLimit=485451360, mergeThreshold=1281591680, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2019-10-04 16:59:43,434 INFO reduce.EventFetcher: attempt_local1647475249_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2019-10-04 16:59:43,451 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1647475249_0001_m_000000_0 decomp: 785 len: 789 to MEMORY
2019-10-04 16:59:43,454 INFO reduce.InMemoryMapOutput: Read 785 bytes from map-output for attempt_local1647475249_0001_m_000000_0
2019-10-04 16:59:43,455 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 785, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->785
2019-10-04 16:59:43,456 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2019-10-04 16:59:43,456 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:43,457 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2019-10-04 16:59:43,462 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:43,462 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 771 bytes
2019-10-04 16:59:43,463 INFO reduce.MergeManagerImpl: Merged 1 segments, 785 bytes to disk to satisfy reduce memory limit
2019-10-04 16:59:43,464 INFO reduce.MergeManagerImpl: Merging 1 files, 789 bytes from disk
2019-10-04 16:59:43,465 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2019-10-04 16:59:43,465 INFO mapred.Merger: Merging 1 sorted segments
2019-10-04 16:59:43,465 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 771 bytes
2019-10-04 16:59:43,466 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:43,469 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python, reducer3.py]
2019-10-04 16:59:43,470 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-10-04 16:59:43,471 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2019-10-04 16:59:43,516 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:43,517 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
2019-10-04 16:59:43,520 INFO streaming.PipeMapRed: MRErrorThread done
2019-10-04 16:59:43,520 INFO streaming.PipeMapRed: Records R/W=50/1
2019-10-04 16:59:43,520 INFO streaming.PipeMapRed: mapRedFinished
2019-10-04 16:59:43,571 INFO mapred.Task: Task:attempt_local1647475249_0001_r_000000_0 is done. And is in the process of committing
2019-10-04 16:59:43,573 INFO mapred.LocalJobRunner: 1 / 1 copied.
2019-10-04 16:59:43,573 INFO mapred.Task: Task attempt_local1647475249_0001_r_000000_0 is allowed to commit now
2019-10-04 16:59:43,588 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1647475249_0001_r_000000_0' to hdfs://localhost:9000/user/hadoop/mapred3
2019-10-04 16:59:43,588 INFO mapred.LocalJobRunner: Records R/W=50/1 > reduce
2019-10-04 16:59:43,588 INFO mapred.Task: Task 'attempt_local1647475249_0001_r_000000_0' done.
2019-10-04 16:59:43,589 INFO mapred.Task: Final Counters for attempt_local1647475249_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=4246
		FILE: Number of bytes written=524583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=79
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=789
		Reduce input records=50
		Reduce output records=5
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=274202624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=79
2019-10-04 16:59:43,589 INFO mapred.LocalJobRunner: Finishing task: attempt_local1647475249_0001_r_000000_0
2019-10-04 16:59:43,589 INFO mapred.LocalJobRunner: reduce task executor complete.
2019-10-04 16:59:44,209 INFO mapreduce.Job: Job job_local1647475249_0001 running in uber mode : false
2019-10-04 16:59:44,211 INFO mapreduce.Job:  map 100% reduce 100%
2019-10-04 16:59:44,213 INFO mapreduce.Job: Job job_local1647475249_0001 completed successfully
2019-10-04 16:59:44,232 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=6882
		FILE: Number of bytes written=1048377
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=268
		HDFS: Number of bytes written=79
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=11
		Map output records=50
		Map output bytes=683
		Map output materialized bytes=789
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=789
		Reduce input records=50
		Reduce output records=5
		Spilled Records=100
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=134
	File Output Format Counters 
		Bytes Written=79
2019-10-04 16:59:44,232 INFO streaming.StreamJob: Output directory: /user/hadoop/mapred3
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:48,469 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob9189464509244628309.jar tmpDir=null
2019-10-04 16:59:49,154 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:49,211 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:49,211 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:49,229 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:49,319 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:53,571 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob7508639047502992503.jar tmpDir=null
2019-10-04 16:59:54,203 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:54,248 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:54,248 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:54,265 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:54,359 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 16:59:58,656 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob4537582818280865513.jar tmpDir=null
2019-10-04 16:59:59,301 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 16:59:59,354 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 16:59:59,355 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 16:59:59,370 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 16:59:59,460 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:03,782 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob5318533648667144717.jar tmpDir=null
2019-10-04 17:00:04,398 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:04,449 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:04,449 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:04,466 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:04,559 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:08,799 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob7755936843356267093.jar tmpDir=null
2019-10-04 17:00:09,420 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:09,464 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:09,464 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:09,480 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:09,569 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:13,785 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob3351291451787304750.jar tmpDir=null
2019-10-04 17:00:14,412 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:14,464 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:14,464 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:14,481 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:14,574 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:18,833 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob7634337484284828976.jar tmpDir=null
2019-10-04 17:00:19,451 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:19,500 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:19,500 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:19,519 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:19,614 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:23,835 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob2501939540680701314.jar tmpDir=null
2019-10-04 17:00:24,462 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:24,519 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:24,519 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:24,542 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:24,636 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:28,903 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob391287093145420387.jar tmpDir=null
2019-10-04 17:00:29,528 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:29,573 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:29,573 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:29,593 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:29,694 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
2019-10-04 17:00:33,954 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/hadoop/Desktop/BigData/PageRank/Matrix/mapper3.py, /home/hadoop/Desktop/BigData/PageRank/Matrix/reducer3.py] [] /tmp/streamjob8822709257998690311.jar tmpDir=null
2019-10-04 17:00:34,542 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2019-10-04 17:00:34,587 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-10-04 17:00:34,587 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-10-04 17:00:34,604 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2019-10-04 17:00:34,706 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/hadoop/mapred3 already exists
Streaming Command Failed!
